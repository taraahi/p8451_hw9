---
title: "Homework 9"
date: "March 27 2022"
output:
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Demonstrate Interaction using Regression Models and Tree-based Methods using Exposome Data from HELIX

### Load .Rdata file and merge into single data frame

Reminder: Merging into a single data frame is optional. Depends upon how you program. This example will assume you've merged everything into a single data frame.

```{r dataprep}
library(tidyverse)
library(caret)
library(rpart.plot)
library(randomForest)
library(caret)
library(gbm)
library(pROC)
library(rpart)
library(Amelia)

#Load data using path of where file is stored
load("./exposome.RData")

#Merge all data frames into a single data frame. FYI, this is just a shortcut by combining baseR with piping from tidyverse. There are other ways of merging across three data frames that are likely more elegant.

studydata<-merge(exposome,phenotype,by="ID") %>% merge(covariates, by="ID")

#Strip off ID Variable
studydata$ID<-NULL

#Partition data for use in demonstration
set.seed(100)
train.indices<-createDataPartition(y=studydata$e3_bw,p=0.7,list=FALSE)
train.data<-studydata[train.indices, ]
test.data<-studydata[-train.indices, ]
```

### Step 1: Data Exploration of Training Data

```{r dataexplore}
#view(train.data)
str(train.data)
#seeing lots of numeric variables with some factor variables
summary(train.data)
#view(codebook)
summary(phenotype)
missmap(train.data)
#observe missing, 0%
```

**PM10 value during pregnancy**
* min: 8.066
* median: 22.796
* mean: 23.393

**NO2 value during pregnancy**
* min: 2.105
* median: 2.959
* mean: 3.001

**PM25 value during pregnancy**
* min: 6.957
* median: 14.880
* mean: 15.002

**Landuse Shannon's Evenness Indexat school**
* min: 0
* median: 0.4015
* mean: 0.3985

**Walkability (postnatal) score**
* min: 0.1
* median: 0.3
* mean: 0.3267

**asthma**
* min: 0
* median: 0
* mean: 0.1091


### Step 2: Research Question

Put your Research Question in this section. It can be a prediction question OR it can be a hypothesis-generating question about either combinations of features or interactions between features.

**Does consumption of legumes, folic acid supplements, fruit, vegetables, and organic foods during pregnancy predict the BMI category of the child at 6-11 years old?**

***

### Step 3: Implement pipeline to address research question

You only need to implement a single algorithm to address your research question.Tune hyperparameters to obtain optimal model in training then evaluate in test set.

```{r algorithm}
set.seed(100)

training.data<-studydata$hs_bmi_c_cat %>% 
  createDataPartition(p=0.7, list=F)

train.data2<-studydata[training.data, ]
test.data2<-studydata[-training.data, ]

train.control.df = trainControl(method = "cv", number = 5, sampling = "up")

mtry.df = c(ncol(train.data)-1, sqrt(ncol(train.data2)-1), 0.5*ncol(train.data2)-1)
mtry.grid = expand.grid(.mtry=mtry.df)
rf.results = train(hs_bmi_c_cat ~., data = train.data2, method = "rf", metric = "Accuracy", tuneGrid = mtry.grid, ntree = 500, trControl = train.control.df)

rf.results$results

plot(1-rf.results$finalModel$err.rate[,1])
varImp(rf.results)
confusionMatrix(rf.results) 
#accuracy 1: 0.8433061
#accuracy 2: 0.9967153
#accuracy 3: 0.9989071

rf.test = predict(rf.results, test.data)
confusionMatrix(rf.test, test.data$hs_bmi_c_cat)
```



### OPTIONAL: Create Models to examine whether two features interact using linear regression

This is a demonstration of code for some interaction analyses.

Note I'm not scaling before running my glm models. If this were a prediction question, I would likely scale so that my coefficients would be interpretable for variable importance. But this is just to show how one codes interaction terms in R using glm. Would be similar if you used within the caret framework. I'm also showing how you would code interaction terms within an elastic net framework using caret.

You can replace the features here with features from your own research question if you'd like to being exploring interactions using linear regression and elastic net. Model.1 and Model.2.a/b are just linear regression while Model 3 is an elastic net that automates examining interactions.

```{r interaction}
#Model 1: Three features, indoor NO2, building density and walkability metric, in relation to child birthweight (I'm assuming measures are consistent pre and postnatal. Likely a bad assumption but just for illustrative purposes)

model.1<-glm(e3_bw~h_NO2_Log+h_builtdens300_preg_Sqrt+h_walkability_mean_preg_None, data=train.data) 
summary(model.1)

#Model 2a: Including an interaction term between two features
model.2a<-glm(e3_bw~h_NO2_Log+h_builtdens300_preg_Sqrt+h_walkability_mean_preg_None+h_NO2_Log*h_builtdens300_preg_Sqrt, data=train.data)
summary(model.2a)

#Model 2b: Including all combinations of two-way interactions using shortcut in glm
model.2b<-glm(e3_bw~(h_NO2_Log+h_builtdens300_preg_Sqrt+h_NO2_Log+h_walkability_mean_preg_None)^2, data=train.data)
summary(model.2b)


#Model 3: Using the caret framework to run an elastic-net with interaction terms between all features using shortcut
set.seed(100)

model.3<- train(
  e3_bw ~(h_NO2_Log+h_builtdens300_preg_Sqrt+h_NO2_Log+h_walkability_mean_preg_None)^2, data = train.data, preProcess="scale", method = "glmnet",
  trControl = trainControl("cv", number = 5),
 tuneLength=10
  )
#Print the values of alpha and lambda that gave best prediction
model.3$bestTune

#Examine model coeficients for variable importance
coef(model.3$finalModel, model.3$bestTune$lambda)

#Predict in test-set
model.3.pred <- model.3 %>% predict(test.data)

# Evaluation metrics and prediction performance
data.frame(
  RMSE = RMSE(model.3.pred, test.data$e3_bw),
  Rsquare = R2(model.3.pred, test.data$e3_bw)
)

```



